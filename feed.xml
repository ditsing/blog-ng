<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://blog.ditsing.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://blog.ditsing.com/" rel="alternate" type="text/html" /><updated>2020-08-29T20:30:45-07:00</updated><id>https://blog.ditsing.com/feed.xml</id><title type="html">ditsing’s Blog</title><subtitle>Talks about random stuff. Study notes, discussions, or argumentations. Posts might be in Chinese.</subtitle><author><name>杨靖</name><email>ditsing [at] gmail.com</email></author><entry><title type="html">Raft, from an engineering perspective</title><link href="https://blog.ditsing.com/2020/08/16/raft-from-an-engineering-perspective.html" rel="alternate" type="text/html" title="Raft, from an engineering perspective" /><published>2020-08-16T09:33:00-07:00</published><updated>2020-08-16T09:33:00-07:00</updated><id>https://blog.ditsing.com/2020/08/16/raft-from-an-engineering-perspective</id><content type="html" xml:base="https://blog.ditsing.com/2020/08/16/raft-from-an-engineering-perspective.html">&lt;p&gt;I recently completed an implementation of the Raft consensus algorithm! It is part of the homework of the online version of &lt;a href=&quot;https://pdos.csail.mit.edu/6.824/&quot;&gt;MIT course 6.824&lt;/a&gt;. It took me 10 months on and off, mostly off.&lt;/p&gt;

&lt;p&gt;The algorithm itself is simple and understandable, as promised by the &lt;a href=&quot;https://raft.github.io/raft.pdf&quot;&gt;paper&lt;/a&gt;. I’d like to summarize my implementation, and share my experience as an engineer implementing it. I wholeheartedly trust the researchers on its correctness. The programming language I used, as required by 6.824, is Go.&lt;/p&gt;

&lt;h2 id=&quot;raft&quot;&gt;Raft&lt;/h2&gt;

&lt;p&gt;Raft stores a replicated log and allows users to add new log entries. Once a log entry is committed, it will stay in the committed state, and survive power outages, server reboots and network failures.&lt;/p&gt;

&lt;p&gt;In practice, Raft keeps the log distributed between a set of servers. One of the servers is elected as the leader, and the rest are followers. The leader is responsible for serving external users, and keeping followers up-to-date on the logs. When the leader dies, a follower can turn into the leader and keep the system running.&lt;/p&gt;

&lt;h2 id=&quot;core-states&quot;&gt;Core States&lt;/h2&gt;

&lt;p&gt;In the implementation, a list of core states are maintained on each server. The states include the current leader, the log entries, the committed log entries, the last term and last vote, the time to start an election, and other logistic information. On each server, the states are guarded by a global lock.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/raft/States.png&quot; alt=&quot;States&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The states on each server are synchronized via two RPCs, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RequestVote&lt;/code&gt;. We’ll discuss those shortly. RPCs (remote procedure calls) are requests and responses sent and received over the network. It is different from function calls and inter-process communication, in the sense that the latency is higher and RPCs could fail arbitrarily because of I/O.&lt;/p&gt;

&lt;p&gt;Looking back at my implementation, I divided Raft into 5 components.&lt;/p&gt;

&lt;h2 id=&quot;election-and-voting&quot;&gt;Election and Voting&lt;/h2&gt;

&lt;p&gt;Responsible for electing a leader to run the system. Arguably the most important part of Raft.&lt;/p&gt;

&lt;p&gt;An election is triggered by a timer. When a follower has not heard from a leader for some time, it starts an election. The follower sends one &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RequestVote&lt;/code&gt; RPC to each of the peers, asking for a vote. If it collects enough votes before someone else starts a new term, then it becomes the new leader. To avoid unnecessary leader changes, the timer will be reset every time a follower hears from the current leader.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/raft/Election.png&quot; alt=&quot;Node C is requesting votes&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Asynchronous operations can lead to many pitfalls. Firstly, If an election is triggered by a timer, we could have a second election triggered when the first is still running. In my implementation, I made an effort to end the prior election before starting a new one. This reduces the noise in the log and simplifies the states that must be considered. It is still possible to code it in a way in which each election dies naturally, though.&lt;/p&gt;

&lt;p&gt;Secondly, latency matters in an unreliable network. A candidate should count votes ASAP when it receives responses from peers, and a newly-elected leader must notify its peers ASAP that it has collected enough votes. Using a channel in those scenarios can introduce significant delays, to the point that elections could not be reliably completed within the usual limit of 150ms ~ 250ms.&lt;/p&gt;

&lt;p&gt;Thirdly, when the system is shut down, an election should be ended as well. Hanging elections confuses peers, and more importantly, also confuses the testing framework of 6.824 that evaluates my implementation.&lt;/p&gt;

&lt;h2 id=&quot;heartbeats&quot;&gt;Heartbeats&lt;/h2&gt;

&lt;p&gt;To ensure that followers know the leader is still alive and functioning, the current leader sends heartbeats to followers. Heartbeats keep the system stable. Followers will not attempt to become a leader while they receive heartbeats. Heartbeats are triggered by the heartbeat timer, which should expire faster than any followers’ election timer. Otherwise those followers will attempt to run an election before the leader sends out the heartbeat.&lt;/p&gt;

&lt;p&gt;In my implementation, one “daemon” goroutine is created for each peer, with its own periodical timer. The advantage of this design is that peers are isolated from each other, so that one lagging peer won’t interfere with other peers.&lt;/p&gt;

&lt;p&gt;The leader also sends an immediate round of heartbeats after it has won an election. This round of RPCs is implemented as a special case. It does not even share code with the periodical version.&lt;/p&gt;

&lt;p&gt;The Raft paper did not design a specific type of RPC for heartbeats. Instead, it uses an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; RPC with no entries to append. The original purpose of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; is to sync log entries.&lt;/p&gt;

&lt;h2 id=&quot;log-entry-syncing&quot;&gt;Log Entry Syncing&lt;/h2&gt;

&lt;p&gt;The leader is responsible for keeping all followers on the same page, by sending out &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; RPCs.&lt;/p&gt;

&lt;p&gt;Unlike heartbeats, log entry syncing is (mainly) triggered by events. Whenever a new log entry is added by a client, the leader needs to replicate it to followers. When things run smoothly, a majority of the followers accept the new log entry. We can then call that entry “committed”. However, because of server crashes and network failures, sometimes followers disagree with the leader. The leader needs to go back in the entry log, find the latest entry that they still agree on (“common ground”), and overwrite all entries after that.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/raft/Sync.png&quot; alt=&quot;AppendEntries&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Finding “common ground” is hard. In my implementation this is a recursive call to the same &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tryAppendEntries&lt;/code&gt; function. The function sends an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; RPC and collects the response. In case of a disagreement, it backtracks up the log entry list exponentially. First it goes back &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt; entry, then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt; entries, then &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X^2&lt;/code&gt; entries and so on. The recursion will not go too deep because of the aggressive “backtrack” behavior. This does mean a lot of the entries will be sent over the network repeatedly, which is less efficient.&lt;/p&gt;

&lt;p&gt;The aggressive backtrack behavior is mainly designed for the limits set by the testing framework. In some extreme tests, an RPC can be delayed by as much as 25ms, or be dropped randomly, or never return. The network is heavily clogged. An election is bound to start in about 150ms after a leader has won, when heartbeat RPCs fail and one of the election timers triggers. That means the current leader only has ~6 RPCs (150ms / 25ms) to communicate with each peer, fewer if some RPCs are randomly lost in the network. The “backtrack” function really needs to go from 1000 to 0 in less than 6 calls. I imagine it will be tuned very differently, if the 95 percentile RPC latency to the same cell is less than 5ms.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; RPC are so important that they must also be monitored by a timer. In some RPC libraries, an RPC can fail with a timeout error, and the timeout can be set by the caller. Unfortunately &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;labrpc.go&lt;/code&gt; that comes with 6.824 does not provide such a nice feature. I implemented the timer as part of the Heartbeat component, which checks the status of log sync before sending out heartbeats. If logs are not in sync, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tryAppendEntries&lt;/code&gt; RPCs are triggered instead of heartbeats.&lt;/p&gt;

&lt;p&gt;Like heartbeats, each peer should have its own ‘daemon’ goroutine that is in charge of log syncing. The heartbeat daemon could share the same goroutine with it. However I did not find a way to wait for both a ticking timer and an event channel at the same time. Let me know if you know how to do that! Another thing is that my obsolete “all peers bundled together” system worked good enough. I did not bother to upgrade.&lt;/p&gt;

&lt;h2 id=&quot;internal-rpc-serving&quot;&gt;Internal RPC Serving&lt;/h2&gt;

&lt;p&gt;We talked about how to send &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AppendEntries&lt;/code&gt; and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RequestVote&lt;/code&gt; RPCs. But how are those RPCs answered?&lt;/p&gt;

&lt;p&gt;The Raft protocol is designed in a way that the answer can be given just by looking at a snapshot of the core states of the receiving peer. There is no waiting required, except for grabbing the lock local to each peer. The only twist is that receiving those two RPC calls can result in a change of core states. If other components are designed to expect state change at any time, there is nothing to worry about.&lt;/p&gt;

&lt;h2 id=&quot;external-rpc-serving&quot;&gt;External RPC Serving&lt;/h2&gt;

&lt;p&gt;Only the leader serves external clients. Each peer should forward “start a new log entry” requests to the current leader. This part is not required by 6.824 and not implemented.&lt;/p&gt;

&lt;p&gt;In reality, clients should communicate with the system via RPCs. Just like internal RPC serving, the implementation should be straightforward.&lt;/p&gt;

&lt;p&gt;The 6.824 testing framework also requires each peer to send a notification via a given Go channel, when a log entry is committed. I don’t think this requirement applies to a real world scenario. This part is implemented as one daemon goroutine on each peer. It is made asynchronous because it communicates with external systems which might be arbitrarily slow. No RPC is involved.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Coding is fun. Writing asynchronous applications is fun. Raft is fun.&lt;/p&gt;

&lt;p&gt;That concludes the summary. Stay tuned for my thoughs and comments!&lt;/p&gt;</content><author><name>杨靖</name><email>ditsing [at] gmail.com</email></author><summary type="html">I recently completed an implementation of the Raft consensus algorithm! It is part of the homework of the online version of MIT course 6.824. It took me 10 months on and off, mostly off. The algorithm itself is simple and understandable, as promised by the paper. I’d like to summarize my implementation, and share my experience as an engineer implementing it. I wholeheartedly trust the researchers on its correctness. The programming language I used, as required by 6.824, is Go. Raft Raft stores a replicated log and allows users to add new log entries. Once a log entry is committed, it will stay in the committed state, and survive power outages, server reboots and network failures. In practice, Raft keeps the log distributed between a set of servers. One of the servers is elected as the leader, and the rest are followers. The leader is responsible for serving external users, and keeping followers up-to-date on the logs. When the leader dies, a follower can turn into the leader and keep the system running. Core States In the implementation, a list of core states are maintained on each server. The states include the current leader, the log entries, the committed log entries, the last term and last vote, the time to start an election, and other logistic information. On each server, the states are guarded by a global lock. The states on each server are synchronized via two RPCs, AppendEntries and RequestVote. We’ll discuss those shortly. RPCs (remote procedure calls) are requests and responses sent and received over the network. It is different from function calls and inter-process communication, in the sense that the latency is higher and RPCs could fail arbitrarily because of I/O. Looking back at my implementation, I divided Raft into 5 components. Election and Voting Responsible for electing a leader to run the system. Arguably the most important part of Raft. An election is triggered by a timer. When a follower has not heard from a leader for some time, it starts an election. The follower sends one RequestVote RPC to each of the peers, asking for a vote. If it collects enough votes before someone else starts a new term, then it becomes the new leader. To avoid unnecessary leader changes, the timer will be reset every time a follower hears from the current leader. Asynchronous operations can lead to many pitfalls. Firstly, If an election is triggered by a timer, we could have a second election triggered when the first is still running. In my implementation, I made an effort to end the prior election before starting a new one. This reduces the noise in the log and simplifies the states that must be considered. It is still possible to code it in a way in which each election dies naturally, though. Secondly, latency matters in an unreliable network. A candidate should count votes ASAP when it receives responses from peers, and a newly-elected leader must notify its peers ASAP that it has collected enough votes. Using a channel in those scenarios can introduce significant delays, to the point that elections could not be reliably completed within the usual limit of 150ms ~ 250ms. Thirdly, when the system is shut down, an election should be ended as well. Hanging elections confuses peers, and more importantly, also confuses the testing framework of 6.824 that evaluates my implementation. Heartbeats To ensure that followers know the leader is still alive and functioning, the current leader sends heartbeats to followers. Heartbeats keep the system stable. Followers will not attempt to become a leader while they receive heartbeats. Heartbeats are triggered by the heartbeat timer, which should expire faster than any followers’ election timer. Otherwise those followers will attempt to run an election before the leader sends out the heartbeat. In my implementation, one “daemon” goroutine is created for each peer, with its own periodical timer. The advantage of this design is that peers are isolated from each other, so that one lagging peer won’t interfere with other peers. The leader also sends an immediate round of heartbeats after it has won an election. This round of RPCs is implemented as a special case. It does not even share code with the periodical version. The Raft paper did not design a specific type of RPC for heartbeats. Instead, it uses an AppendEntries RPC with no entries to append. The original purpose of AppendEntries is to sync log entries. Log Entry Syncing The leader is responsible for keeping all followers on the same page, by sending out AppendEntries RPCs. Unlike heartbeats, log entry syncing is (mainly) triggered by events. Whenever a new log entry is added by a client, the leader needs to replicate it to followers. When things run smoothly, a majority of the followers accept the new log entry. We can then call that entry “committed”. However, because of server crashes and network failures, sometimes followers disagree with the leader. The leader needs to go back in the entry log, find the latest entry that they still agree on (“common ground”), and overwrite all entries after that. Finding “common ground” is hard. In my implementation this is a recursive call to the same tryAppendEntries function. The function sends an AppendEntries RPC and collects the response. In case of a disagreement, it backtracks up the log entry list exponentially. First it goes back 1 entry, then X entries, then X^2 entries and so on. The recursion will not go too deep because of the aggressive “backtrack” behavior. This does mean a lot of the entries will be sent over the network repeatedly, which is less efficient. The aggressive backtrack behavior is mainly designed for the limits set by the testing framework. In some extreme tests, an RPC can be delayed by as much as 25ms, or be dropped randomly, or never return. The network is heavily clogged. An election is bound to start in about 150ms after a leader has won, when heartbeat RPCs fail and one of the election timers triggers. That means the current leader only has ~6 RPCs (150ms / 25ms) to communicate with each peer, fewer if some RPCs are randomly lost in the network. The “backtrack” function really needs to go from 1000 to 0 in less than 6 calls. I imagine it will be tuned very differently, if the 95 percentile RPC latency to the same cell is less than 5ms. AppendEntries RPC are so important that they must also be monitored by a timer. In some RPC libraries, an RPC can fail with a timeout error, and the timeout can be set by the caller. Unfortunately labrpc.go that comes with 6.824 does not provide such a nice feature. I implemented the timer as part of the Heartbeat component, which checks the status of log sync before sending out heartbeats. If logs are not in sync, tryAppendEntries RPCs are triggered instead of heartbeats. Like heartbeats, each peer should have its own ‘daemon’ goroutine that is in charge of log syncing. The heartbeat daemon could share the same goroutine with it. However I did not find a way to wait for both a ticking timer and an event channel at the same time. Let me know if you know how to do that! Another thing is that my obsolete “all peers bundled together” system worked good enough. I did not bother to upgrade. Internal RPC Serving We talked about how to send AppendEntries and RequestVote RPCs. But how are those RPCs answered? The Raft protocol is designed in a way that the answer can be given just by looking at a snapshot of the core states of the receiving peer. There is no waiting required, except for grabbing the lock local to each peer. The only twist is that receiving those two RPC calls can result in a change of core states. If other components are designed to expect state change at any time, there is nothing to worry about. External RPC Serving Only the leader serves external clients. Each peer should forward “start a new log entry” requests to the current leader. This part is not required by 6.824 and not implemented. In reality, clients should communicate with the system via RPCs. Just like internal RPC serving, the implementation should be straightforward. The 6.824 testing framework also requires each peer to send a notification via a given Go channel, when a log entry is committed. I don’t think this requirement applies to a real world scenario. This part is implemented as one daemon goroutine on each peer. It is made asynchronous because it communicates with external systems which might be arbitrarily slow. No RPC is involved. Conclusion Coding is fun. Writing asynchronous applications is fun. Raft is fun. That concludes the summary. Stay tuned for my thoughs and comments!</summary></entry><entry><title type="html">“文化不适”</title><link href="https://blog.ditsing.com/%E5%B7%A5%E4%BD%9C/2020/08/15/%E6%96%87%E5%8C%96%E4%B8%8D%E9%80%82.html" rel="alternate" type="text/html" title="“文化不适”" /><published>2020-08-15T06:24:00-07:00</published><updated>2020-08-15T06:24:00-07:00</updated><id>https://blog.ditsing.com/%E5%B7%A5%E4%BD%9C/2020/08/15/%E6%96%87%E5%8C%96%E4%B8%8D%E9%80%82</id><content type="html" xml:base="https://blog.ditsing.com/%E5%B7%A5%E4%BD%9C/2020/08/15/%E6%96%87%E5%8C%96%E4%B8%8D%E9%80%82.html">&lt;p&gt;标题是从 Culture Fit 生硬翻译过来的。哦，应该是 unfit。&lt;/p&gt;

&lt;p&gt;&lt;!--more--&gt;&lt;/p&gt;

&lt;p&gt;我最近（9个月前）换了组。新的组里有一大一小两个 TL （Tech Lead，可以翻译成“技术带头人”）。就管他们叫大小王吧，国王的王。在这九个月里，我观察到了一些让我不适的“文化”。&lt;/p&gt;

&lt;p&gt;小王和我做项目。周一，他要求我实现一个改进版的想法，我和他深入讨论（争执）了之后，觉得有一定道理。他也跟合作的姐妹组开了会，通报了他的想法，得到了肯定。小王对这个想法相当兴奋。&lt;/p&gt;

&lt;p&gt;周五我们和大王一起开会，讨论我们的项目。会议进行到一半，大王简短地问为什么要改进，原来的计划也很好嘛。紧接着大王提议可以按原来的计划做，然后再做改进版。小王当场把我们的下一步计划改了回去，一句多余的解释都没有。接受程度之高让我吃了一惊。&lt;/p&gt;

&lt;p&gt;这已经不是我第一次遇到这种情景了。私下里，我跟大王提到对这种“不解释”行为的不解。大王说他自己没有注意到类似的事情，也没有在和其他 leader 开会的时候注意到类似的事情。他的解释是，可能只是工作习惯不同，”picking the right battle to fight”，也可能是为了尽快争取支持，还可能是因为两个提议差别不大，更可能是因为没有时间讨论。我说那我还是有挺多需要学习的。&lt;/p&gt;

&lt;p&gt;上次发生这种事的时候，小王的指导的一个项目被搁置，负责执行的同事换了主力项目。当时开会甚至都不是为了讨论小王的项目，负责执行的同事也没有在场。我在我司这么多年，从来没听说过这种事情。&lt;/p&gt;

&lt;p&gt;我还遇到过，小王下手改我的个人备忘录，告诉我下周要做什么，下下周要做什么。我跟我老板抗议，她说她也会这样做。嗯，仔细想想她也经常提非常非常细节的要求。&lt;/p&gt;

&lt;p&gt;大小两个王都是 L5，我也是 L5。大王还比较年轻一点。&lt;/p&gt;

&lt;p&gt;真的不适。&lt;/p&gt;</content><author><name>杨靖</name><email>ditsing [at] gmail.com</email></author><category term="工作" /><category term="人到中年" /><summary type="html">标题是从 Culture Fit 生硬翻译过来的。哦，应该是 unfit。</summary></entry></feed>